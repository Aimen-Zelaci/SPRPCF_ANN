1. Y. Kiarashinejad, M. Zandehshahvar, S. Abdollahramezani, O. Hemmatyar, R. Pourabolghasem, and A. Adibi,
“Knowledge discovery in nanophotonics using geometric deep learning,” arXiv preprint arXiv:1909.07330 (2019)

2. T. Asano and S. Noda, “Optimization of photonic crystal nanocavities based on deep learning,” Opt. Express 26(25),
32704–32717 (2018).

3. S.  Chugh,  A.  Gulistan,  S.  Ghosh,  B.M.A.  Rahman,  Machine  learning  approach  for computing optical properties of a photonic crystal fiber, Opt. Express, 27 (2019) 36414-36425.

4. Generative Adversarial Networks
Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio
(Submitted on 10 Jun 2014) arXiv

5. Schlegl T., Seeböck P., Waldstein S.M., Schmidt-Erfurth U., Langs G. (2017) Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery. In: Niethammer M. et al. (eds) Information Processing in Medical Imaging. IPMI 2017. Lecture Notes in Computer Science, vol 10265. Springer, Cham

6. Zheng, Z.; Zheng, L.; and Yang, Y. 2017. Unlabeled samples generated by gan improve the person re-identification
baseline in vitro. In ICCV.
Effective Data Augmentation with Multi-Domain Learning GANs
Shin'ya Yamaguchi, Sekitoshi Kanai, Takeharu Eda
(Submitted on 25 Dec 2019)

7. Synthetic Data Augmentation using GAN for Improved Liver Lesion Classification
Maayan Frid-Adar, Eyal Klang, Michal Amitai, Jacob Goldberger, Hayit Greenspan
(Submitted on 8 Jan 2018)

8. Data Augmentation Using GANs
Fabio Henrique Kiyoiti dos Santos Tanaka, Claus Aranha
(Submitted on 19 Apr 2019)

9. The Effectiveness of Data Augmentation in Image Classification using Deep Learning
Luis Perez, Jason Wang
(Submitted on 13 Dec 2017)

10. Ravuri, S., and Vinyals, O. 2019. Seeing is not necessarily
believing: Limitations of biggans for data augmentation. In
ICLR.

11. Shmelkov, K.; Schmid, C.; and Alahari, K. 2018. How good
is my gan? In ECCV.

12. Sampling Strategies for GAN Synthetic Data
Binod Bhattarai, Seungryul Baek, Rumeysa Bodur, Tae-Kyun Kim
(Submitted on 10 Sep 2019)

13. Adam: A Method for Stochastic Optimization
Diederik P. Kingma, Jimmy Ba
(Submitted on 22 Dec 2014 (v1), last revised 30 Jan 2017 (this version, v9)) arXiv:1412.6980

14. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
Sergey Ioffe, Christian Szegedy
(Submitted on 11 Feb 2015 (v1), last revised 2 Mar 2015 (this version, v3)) arXiv:1502.03167

15. Wasserstein GAN
Martin Arjovsky, Soumith Chintala, Léon Bottou
(Submitted on 26 Jan 2017 (v1), last revised 6 Dec 2017 (this version, v3)) arXiv:1701.07875

16. Improved Training of Wasserstein GANs
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, Aaron Courville
(Submitted on 31 Mar 2017 (v1), last revised 25 Dec 2017 (this version, v3)) arXiv:1704.00028

17. Revisiting Small Batch Training for Deep Neural Networks
Dominic Masters, Carlo Luschi
(Submitted on 20 Apr 2018)

18. On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima
Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, Ping Tak Peter Tang
(Submitted on 15 Sep 2016 (v1), last revised 9 Feb 2017 (this version, v2))

19. Train longer, generalize better: closing the
generalization gap in large batch training of neural
networks
(Elad Hoffer, Itay Hubara, Daniel Soudry
1 Jan 2018)

20. Neural Networks and Deep Learning by Michael Nielsen / Dec 2019, chapters {1, 2, 3, 4}
    http://neuralnetworksanddeeplearning.com/

